{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "90unKHY8m687"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from os import path, makedirs, remove\n",
        "\n",
        "from utilities.utils import pad_inputs\n",
        "from utilities.initializers import glorot_uniform\n",
        "from utilities.settings import get_layer_num, inc_layer_num\n",
        "\n",
        "\n",
        "class Convolution:\n",
        "    def __init__(self, filters, kernel_shape=(3, 3), padding='valid', stride=1, name=None):\n",
        "        self.params = {\n",
        "            'filters': filters,\n",
        "            'padding': padding,\n",
        "            'kernel_shape': kernel_shape,\n",
        "            'stride': stride\n",
        "        }\n",
        "        self.cache = {}\n",
        "        self.rmsprop_cache = {}\n",
        "        self.momentum_cache = {}\n",
        "        self.grads = {}\n",
        "        self.has_units = True\n",
        "        self.name = name\n",
        "        self.type = 'conv'\n",
        "\n",
        "   \n",
        "   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABATnvNun6Af"
      },
      "source": [
        " def has_weights(self):\n",
        "        return self.has_units\n",
        "\n",
        "    def save_weights(self, dump_path):\n",
        "        dump_cache = {\n",
        "            'cache': self.cache,\n",
        "            'grads': self.grads,\n",
        "            'momentum': self.momentum_cache,\n",
        "            'rmsprop': self.rmsprop_cache\n",
        "        }\n",
        "        save_path = path.join(dump_path, self.name+'.pickle')\n",
        "        makedirs(path.dirname(save_path), exist_ok=True)\n",
        "        remove(save_path)\n",
        "        with open(save_path, 'wb') as d:\n",
        "            pickle.dump(dump_cache, d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ8cjbUWn2gC"
      },
      "source": [
        " def load_weights(self, dump_path):\n",
        "        if self.name is None:\n",
        "            self.name = '{}_{}'.format(self.type, get_layer_num(self.type))\n",
        "            inc_layer_num(self.type)\n",
        "        read_path = path.join(dump_path, self.name+'.pickle')\n",
        "        with open(read_path, 'rb') as r:\n",
        "            dump_cache = pickle.load(r)\n",
        "        self.cache = dump_cache['cache']\n",
        "        self.grads = dump_cache['grads']\n",
        "        self.momentum_cache = dump_cache['momentum']\n",
        "        self.rmsprop_cache = dump_cache['rmsprop']\n",
        "\n",
        "    def conv_single_step(self, input, W, b):\n",
        "        '''\n",
        "        Function to apply one filter to input slice.\n",
        "        :param input:[numpy array]: slice of input data of shape (f, f, n_C_prev)\n",
        "        :param W:[numpy array]: One filter of shape (f, f, n_C_prev)\n",
        "        :param b:[numpy array]: Bias value for the filter. Shape (1, 1, 1)\n",
        "        :return:\n",
        "        '''\n",
        "        return np.sum(np.multiply(input, W)) + float(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11-tEfs9nWwq"
      },
      "source": [
        "    def forward_propagate(self, X, save_cache=False):\n",
        "        '''\n",
        "\n",
        "        :param X:\n",
        "        :param save_cache:\n",
        "        :return:\n",
        "        '''\n",
        "        if self.name is None:\n",
        "            self.name = '{}_{}'.format(self.type, get_layer_num(self.type))\n",
        "            inc_layer_num(self.type)\n",
        "\n",
        "        (num_data_points, prev_height, prev_width, prev_channels) = X.shape\n",
        "        filter_shape_h, filter_shape_w = self.params['kernel_shape']\n",
        "\n",
        "        if 'W' not in self.params:\n",
        "            shape = (filter_shape_h, filter_shape_w, prev_channels, self.params['filters'])\n",
        "            self.params['W'], self.params['b'] = glorot_uniform(shape=shape)\n",
        "\n",
        "        if self.params['padding'] == 'same':\n",
        "            pad_h = int(((prev_height - 1)*self.params['stride'] + filter_shape_h - prev_height) / 2)\n",
        "            pad_w = int(((prev_width - 1)*self.params['stride'] + filter_shape_w - prev_width) / 2)\n",
        "            n_H = prev_height\n",
        "            n_W = prev_width\n",
        "        else:\n",
        "            pad_h = 0\n",
        "            pad_w = 0\n",
        "            n_H = int((prev_height - filter_shape_h) / self.params['stride']) + 1\n",
        "            n_W = int((prev_width - filter_shape_w) / self.params['stride']) + 1\n",
        "\n",
        "        self.params['pad_h'], self.params['pad_w'] = pad_h, pad_w\n",
        "\n",
        "        Z = np.zeros(shape=(num_data_points, n_H, n_W, self.params['filters']))\n",
        "\n",
        "        X_pad = pad_inputs(X, (pad_h, pad_w))\n",
        "\n",
        "        for i in range(num_data_points):\n",
        "            x = X_pad[i]\n",
        "            for h in range(n_H):\n",
        "                for w in range(n_W):\n",
        "                    vert_start = self.params['stride'] * h\n",
        "                    vert_end = vert_start + filter_shape_h\n",
        "                    horiz_start = self.params['stride'] * w\n",
        "                    horiz_end = horiz_start + filter_shape_w\n",
        "\n",
        "                    for c in range(self.params['filters']):\n",
        "\n",
        "                        x_slice = x[vert_start: vert_end, horiz_start: horiz_end, :]\n",
        "\n",
        "                        Z[i, h, w, c] = self.conv_single_step(x_slice, self.params['W'][:, :, :, c],\n",
        "                                                              self.params['b'][:, :, :, c])\n",
        "\n",
        "        if save_cache:\n",
        "            self.cache['A'] = X\n",
        "\n",
        "        return Z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzxZrfagnW3z"
      },
      "source": [
        "    def back_propagate(self, dZ):\n",
        "        '''\n",
        "\n",
        "        :param dZ:\n",
        "        :return:\n",
        "        '''\n",
        "        A = self.cache['A']\n",
        "        filter_shape_h, filter_shape_w = self.params['kernel_shape']\n",
        "        pad_h, pad_w = self.params['pad_h'], self.params['pad_w']\n",
        "\n",
        "        (num_data_points, prev_height, prev_width, prev_channels) = A.shape\n",
        "\n",
        "        dA = np.zeros((num_data_points, prev_height, prev_width, prev_channels))\n",
        "        self.grads = self.init_cache()\n",
        "\n",
        "        A_pad = pad_inputs(A, (pad_h, pad_w))\n",
        "        dA_pad = pad_inputs(dA, (pad_h, pad_w))\n",
        "\n",
        "        for i in range(num_data_points):\n",
        "            a_pad = A_pad[i]\n",
        "            da_pad = dA_pad[i]\n",
        "\n",
        "            for h in range(prev_height):\n",
        "                for w in range(prev_width):\n",
        "\n",
        "                    vert_start = self.params['stride'] * h\n",
        "                    vert_end = vert_start + filter_shape_h\n",
        "                    horiz_start = self.params['stride'] * w\n",
        "                    horiz_end = horiz_start + filter_shape_w\n",
        "\n",
        "                    for c in range(self.params['filters']):\n",
        "                        a_slice = a_pad[vert_start: vert_end, horiz_start: horiz_end, :]\n",
        "\n",
        "                        da_pad[vert_start:vert_end, horiz_start:horiz_end, :] += self.params['W'][:, :, :, c] * dZ[i, h, w, c]\n",
        "                        self.grads['dW'][:, :, :, c] += a_slice * dZ[i, h, w, c]\n",
        "                        self.grads['db'][:, :, :, c] += dZ[i, h, w, c]\n",
        "            dA[i, :, :, :] = da_pad[pad_h: -pad_h, pad_w: -pad_w, :]\n",
        "\n",
        "        return dA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxeXZCgBnW-h"
      },
      "source": [
        " def init_cache(self):\n",
        "        cache = dict()\n",
        "        cache['dW'] = np.zeros_like(self.params['W'])\n",
        "        cache['db'] = np.zeros_like(self.params['b'])\n",
        "        return cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUQKHXNhnXtZ"
      },
      "source": [
        " def momentum(self, beta=0.9):\n",
        "        if not self.momentum_cache:\n",
        "            self.momentum_cache = self.init_cache()\n",
        "        self.momentum_cache['dW'] = beta * self.momentum_cache['dW'] + (1 - beta) * self.grads['dW']\n",
        "        self.momentum_cache['db'] = beta * self.momentum_cache['db'] + (1 - beta) * self.grads['db']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is9IBDEKnX2j"
      },
      "source": [
        "\n",
        "    def rmsprop(self, beta=0.999, amsprop=True):\n",
        "        if not self.rmsprop_cache:\n",
        "            self.rmsprop_cache = self.init_cache()\n",
        "\n",
        "        new_dW = beta * self.rmsprop_cache['dW'] + (1 - beta) * (self.grads['dW']**2)\n",
        "        new_db = beta * self.rmsprop_cache['db'] + (1 - beta) * (self.grads['db']**2)\n",
        "\n",
        "        if amsprop:\n",
        "            self.rmsprop_cache['dW'] = np.maximum(self.rmsprop_cache['dW'], new_dW)\n",
        "            self.rmsprop_cache['db'] = np.maximum(self.rmsprop_cache['db'], new_db)\n",
        "        else:\n",
        "            self.rmsprop_cache['dW'] = new_dW\n",
        "            self.rmsprop_cache['db'] = new_db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4ibkDMlnX_v"
      },
      "source": [
        "\n",
        "    def apply_grads(self, learning_rate=0.001, l2_penalty=1e-4, optimization='adam', epsilon=1e-8,\n",
        "                    correct_bias=False, beta1=0.9, beta2=0.999, iter=999):\n",
        "        if optimization != 'adam':\n",
        "            self.params['W'] -= learning_rate * (self.grads['dW'] + l2_penalty * self.params['W'])\n",
        "            self.params['b'] -= learning_rate * (self.grads['db'] + l2_penalty * self.params['b'])\n",
        "\n",
        "        else:\n",
        "            if correct_bias:\n",
        "                W_first_moment = self.momentum_cache['dW'] / (1 - beta1 ** iter)\n",
        "                b_first_moment = self.momentum_cache['db'] / (1 - beta1 ** iter)\n",
        "                W_second_moment = self.rmsprop_cache['dW'] / (1 - beta2 ** iter)\n",
        "                b_second_moment = self.rmsprop_cache['db'] / (1 - beta2 ** iter)\n",
        "            else:\n",
        "                W_first_moment = self.momentum_cache['dW']\n",
        "                b_first_moment = self.momentum_cache['db']\n",
        "                W_second_moment = self.rmsprop_cache['dW']\n",
        "                b_second_moment = self.rmsprop_cache['db']\n",
        "\n",
        "            W_learning_rate = learning_rate / (np.sqrt(W_second_moment) + epsilon)\n",
        "            b_learning_rate = learning_rate / (np.sqrt(b_second_moment) + epsilon)\n",
        "\n",
        "            self.params['W'] -= W_learning_rate * (W_first_moment + l2_penalty * self.params['W'])\n",
        "            self.params['b'] -= b_learning_rate * (b_first_moment + l2_penalty * self.params['b'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}